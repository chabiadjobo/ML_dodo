{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1- Les bibliothèques à importer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ydata_profiling as yp\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2- Importation, compréhension, Prétraitement et Transformation des données des bases de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-1 Importation et compréhension des bases de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('dataset.csv', delimiter=',', quotechar='\"')\n",
    "datasetsupplement = pd.read_csv('dataset_supplement.csv', delimiter=',', quotechar='\"')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit de deux bases de données liées par la variable id dans la base dataset et movie_id dans la base dataset_supplement. Ces deux bases de données donnent des informations sur 4803 films. un premier constat, certaines variables (exemple des variables actors, production-crew, attributs_spoken_languages, etc.) contiennent une liste de dictionnaires, où chaque dictionnaire représente un unité et contient plusieurs attributs. Il est donc indispensable d'extraire les informations pertinentes des données brutes de ces variables pour les rendre exploitables pour le machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-2 Prétraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première étape est d'identifier ces variables, surtout celle qui sont utile pour le machine learning, ensuite d'identifier les informations à extraire. Les variables concernées sont : \n",
    "1 - pour la base dataset : spoken_languages, countries_of_production, production, keywords et genres ; \n",
    "2 - pour la base dataset_supplement : actors et production_crew.\n",
    "\n",
    "Pour la suite, les vafriables production et keywords ne seront pas pris en compte à cause du très grands nombre de modalités"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour extraire les modalités d'un attribut complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extraire_modalites(row, variable, attribut):\n",
    "    elements = eval(row[variable])\n",
    "    modalites = set()\n",
    "    for element in elements:\n",
    "        if attribut in element:\n",
    "            modalites.add(element[attribut])\n",
    "    return modalites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour compter les occurrences de chaque modalité"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compter_occurrences(row, variable, attribut, modalite):\n",
    "    elements = eval(row[variable])\n",
    "    nb_occurrences = sum(1 for element in elements if attribut in element and element[attribut] == modalite)\n",
    "    return nb_occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction pour ajouter les nouvelles variables à la base de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ajouter_nouvelles_variables(data, variable, attribut):\n",
    "    modalites = set()\n",
    "    for index, row in data.iterrows():\n",
    "        modalites.update(extraire_modalites(row, variable, attribut))\n",
    "    for modalite in modalites:\n",
    "        nom_colonne = variable + '_' + attribut + '_' + str(modalite)\n",
    "        data[nom_colonne] = data.apply(lambda x: compter_occurrences(x, variable, attribut, modalite), axis=1)\n",
    "    # Ajouter une variable avec le nombre de modalités par attribut\n",
    "    Nb_modalite_nom_colonne = 'Nb_modalite' + variable + '_' + attribut\n",
    "    data[Nb_modalite_nom_colonne] = data.apply(lambda x: len(extraire_modalites(x, variable, attribut)), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Liste des attributs à considérer par variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dans la base dataset\n",
    "attributs_actors = ['gender']\n",
    "attributs_production_crew = ['department', 'gender']\n",
    "\n",
    "# Dans la base supplémentaire\n",
    "attributs_spoken_languages = ['name']\n",
    "attributs_countries_of_production = ['name']\n",
    "attributs_genres = ['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraction des informations et création des variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribut in attributs_production_crew:\n",
    "    ajouter_nouvelles_variables(datasetsupplement, 'production_crew', attribut)\n",
    "\n",
    "for attribut in attributs_actors:\n",
    "    ajouter_nouvelles_variables(datasetsupplement, 'actors', attribut)\n",
    "\n",
    "for attribut in attributs_spoken_languages:\n",
    "    ajouter_nouvelles_variables(dataset, 'spoken_languages', attribut)\n",
    "\n",
    "for attribut in attributs_countries_of_production:\n",
    "    ajouter_nouvelles_variables(dataset, 'countries_of_production', attribut)\n",
    "\n",
    "for attribut in attributs_genres:\n",
    "    ajouter_nouvelles_variables(dataset, 'genres', attribut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder la nouvelle base de données\n",
    "datasetsupplement.to_csv('datasetsupplement_new.csv', index=False)\n",
    "dataset.to_csv('dataset_new.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Sélection des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fusion des bases de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fusionner les DataFrames sur les colonnes \"id\" et \"movie_id\"\n",
    "merged_dataset = pd.merge(dataset, datasetsupplement, left_on='id', right_on='movie_id')\n",
    "\n",
    "# Réorganiser les colonnes pour déplacer la colonne \"id\" en début de base de données\n",
    "merged_dataset = merged_dataset[['id'] + [col for col in merged_dataset.columns if col != 'id']]\n",
    "\n",
    "# Supprimer la colonne \"movie_id\" qui est devenue redondante après la fusion\n",
    "merged_dataset.drop(columns=['movie_id', 'Unnamed: 0_x', 'Unnamed: 0_y'], inplace=True)\n",
    "\n",
    "# Sauvegarder le DataFrame fusionné dans un nouveau fichier CSV\n",
    "merged_dataset.to_csv('merged_dataset.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppression des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1- les variables suivantes vont êtres supprimées dans la mesures où les informations utiles ont étéextraites : 'production_crew', 'actors', 'spoken_languages', 'genres',\n",
    "2 - Les variables suivantes sont supprimées parce que trop d'information : 'title_x', 'tagline', \n",
    "3 - Les variables créées pour chaque langue ont été supprimées compte tenu du nombre de langue élevé. Seule la variables renseignant chaque le nombre de langue a été maintenu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des variables à supprimer\n",
    "variables_a_supprimer = ['production_crew', 'actors', 'spoken_languages', 'genres', 'title_x', 'tagline', 'overview' , 'original_title' , 'homepage' , 'spoken_languages_name_', 'spoken_languages_name_Bosanski', 'spoken_languages_name_普通话', 'spoken_languages_name_广州话 / 廣州話', 'spoken_languages_name_తెలుగు', 'spoken_languages_name_Slovenščina', 'spoken_languages_name_Íslenska', 'spoken_languages_name_বাংলা', 'spoken_languages_name_svenska', 'spoken_languages_name_Srpski', 'spoken_languages_name_Slovenčina', 'spoken_languages_name_Gaeilge', 'spoken_languages_name_Català', 'spoken_languages_name_Latin', 'spoken_languages_name_हिन्दी', 'spoken_languages_name_فارسی', 'spoken_languages_name_Polski', 'spoken_languages_name_Türkçe', 'spoken_languages_name_Bamanankan', 'spoken_languages_name_No Language', 'spoken_languages_name_Português', 'spoken_languages_name_Bahasa indonesia', 'spoken_languages_name_Español', 'spoken_languages_name_Nederlands', 'spoken_languages_name_български език', 'spoken_languages_name_suomi', 'spoken_languages_name_ภาษาไทย', 'spoken_languages_name_العربية', 'spoken_languages_name_Esperanto', 'spoken_languages_name_isiZulu', 'spoken_languages_name_Český', 'spoken_languages_name_日本語', 'spoken_languages_name_اردو', 'spoken_languages_name_қазақ', 'spoken_languages_name_Dansk', 'spoken_languages_name_ქართული', 'spoken_languages_name_한국어/조선말', 'spoken_languages_name_Tiếng Việt', 'spoken_languages_name_Italiano', 'spoken_languages_name_shqip', 'spoken_languages_name_??????', 'spoken_languages_name_Wolof', 'spoken_languages_name_Somali', 'spoken_languages_name_پښتو', 'spoken_languages_name_Français', 'spoken_languages_name_Cymraeg', 'spoken_languages_name_English', 'spoken_languages_name_Română', 'spoken_languages_name_Pусский', 'spoken_languages_name_Eesti', 'spoken_languages_name_Deutsch', 'spoken_languages_name_ਪੰਜਾਬੀ', 'spoken_languages_name_Hrvatski', 'spoken_languages_name_ελληνικά', 'spoken_languages_name_Norsk', 'spoken_languages_name_Afrikaans', 'spoken_languages_name_Kiswahili', 'spoken_languages_name_עִבְרִית', 'spoken_languages_name_Galego', 'spoken_languages_name_தமிழ்', 'spoken_languages_name_Magyar', 'spoken_languages_name_Український', 'countries_of_production_name_Colombia', 'countries_of_production_name_Singapore', 'countries_of_production_name_Pakistan', 'countries_of_production_name_Romania', 'countries_of_production_name_Thailand', 'countries_of_production_name_Czech Republic', 'countries_of_production_name_United States of America', 'countries_of_production_name_Slovakia', 'countries_of_production_name_Sweden', 'countries_of_production_name_Malta', 'countries_of_production_name_United Arab Emirates', 'countries_of_production_name_Bulgaria', 'countries_of_production_name_Poland', 'countries_of_production_name_Kazakhstan', 'countries_of_production_name_Spain', 'countries_of_production_name_India', 'countries_of_production_name_Iceland', 'countries_of_production_name_Ecuador', 'countries_of_production_name_France', 'countries_of_production_name_China', 'countries_of_production_name_Jordan', 'countries_of_production_name_Finland', 'countries_of_production_name_Kyrgyz Republic', 'countries_of_production_name_Japan', 'countries_of_production_name_Aruba', 'countries_of_production_name_Belgium', 'countries_of_production_name_Austria', 'countries_of_production_name_South Africa', 'countries_of_production_name_Hungary', 'countries_of_production_name_Denmark', 'countries_of_production_name_Greece', 'countries_of_production_name_Lithuania', 'countries_of_production_name_Guadaloupe', 'countries_of_production_name_Iran', 'countries_of_production_name_Bolivia', 'countries_of_production_name_Netherlands', 'countries_of_production_name_Cameroon', 'countries_of_production_name_Tunisia', 'countries_of_production_name_Luxembourg', 'countries_of_production_name_Bhutan', 'countries_of_production_name_Dominican Republic', 'countries_of_production_name_Bosnia and Herzegovina', 'countries_of_production_name_Morocco', 'countries_of_production_name_Taiwan', 'countries_of_production_name_New Zealand', 'countries_of_production_name_Nigeria', 'countries_of_production_name_Slovenia', 'countries_of_production_name_Malaysia', 'countries_of_production_name_Monaco', 'countries_of_production_name_Brazil', 'countries_of_production_name_Peru', 'countries_of_production_name_Cambodia', 'countries_of_production_name_Serbia and Montenegro', 'countries_of_production_name_Cyprus', 'countries_of_production_name_Afghanistan', 'countries_of_production_name_Angola', 'countries_of_production_name_Fiji', 'countries_of_production_name_Israel', 'countries_of_production_name_Lebanon', 'countries_of_production_name_Canada', 'countries_of_production_name_Russia', 'countries_of_production_name_Indonesia', 'countries_of_production_name_Bahamas', 'countries_of_production_name_Kenya', 'countries_of_production_name_Italy', 'countries_of_production_name_Germany', 'countries_of_production_name_South Korea', 'countries_of_production_name_Libyan Arab Jamahiriya', 'countries_of_production_name_Norway', 'countries_of_production_name_Ukraine', 'countries_of_production_name_Mexico', 'countries_of_production_name_Serbia', 'countries_of_production_name_Turkey', 'countries_of_production_name_Hong Kong', 'countries_of_production_name_United Kingdom', 'countries_of_production_name_Switzerland', 'countries_of_production_name_Guyana', 'countries_of_production_name_Dominica', 'countries_of_production_name_Jamaica', 'countries_of_production_name_Ireland', 'countries_of_production_name_Australia', 'countries_of_production_name_Argentina', 'countries_of_production_name_Chile', 'countries_of_production_name_Algeria', 'countries_of_production_name_Egypt', 'countries_of_production_name_Portugal', 'countries_of_production_name_Philippines', 'countries_of_production_name_Panama', 'Nb_modaliteproduction_crew_gender', 'Nb_modaliteactors_gender', ]\n",
    "\n",
    "# Supprimer les variables spécifiées\n",
    "merged_dataset.drop(columns=variables_a_supprimer, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset.to_csv('merged_dataset2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37f1398e469485f8a4f81a45cd6c789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ayedesso/9CEA8269EA823F8E/Travail_ubuntu/Autres_travaux/ML_dodo/venvir/lib/python3.10/site-packages/ydata_profiling/model/correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(correlations={\"auto\": {\"calculate\": False}})`\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: 'en'')\n",
      "  warnings.warn(\n",
      "/media/ayedesso/9CEA8269EA823F8E/Travail_ubuntu/Autres_travaux/ML_dodo/venvir/lib/python3.10/site-packages/seaborn/matrix.py:260: FutureWarning: Format strings passed to MaskedConstant are ignored, but in future may error or produce different behavior\n",
      "  annotation = (\"{:\" + self.fmt + \"}\").format(val)\n",
      "/media/ayedesso/9CEA8269EA823F8E/Travail_ubuntu/Autres_travaux/ML_dodo/venvir/lib/python3.10/site-packages/ydata_profiling/model/missing.py:78: UserWarning: There was an attempt to generate the Heatmap missing values diagrams, but this failed.\n",
      "To hide this warning, disable the calculation\n",
      "(using `df.profile_report(missing_diagrams={\"Heatmap\": False}`)\n",
      "If this is problematic for your use case, please report this as an issue:\n",
      "https://github.com/ydataai/ydata-profiling/issues\n",
      "(include the error message: 'could not convert string to float: '--'')\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af39dcc865040539d57ad221b8bf122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35b12584a2404c18b6b9a044e0f10254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render widgets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85c21cf1e3a94667a18da1fab43a6e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48230b96c9e3476d8e09939a16f2d2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97ee35d4e6fa44bc855923b33d01b8b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset.describe()\n",
    "profile = ProfileReport(merged_dataset)\n",
    "profile.to_widgets()\n",
    "profile.to_file(\"rapport.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse du rapport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les données présentent une qualité globalement satisfaisante, avec l'absence de valeurs en double et un faible pourcentage de cellules manquantes (0.4%). La diversité des types de variables, comprenant des variables numériques, catégoriques, de type DateTime et de type texte, suggère la nécessité d'utiliser une gamme variée de techniques d'analyse et de modélisation pour explorer et comprendre les données. Avec 4803 observations, l'ensemble de données est de taille moyenne à grande, offrant suffisamment de données pour mener des analyses significatives et construire des modèles prédictifs robustes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les alertes fournies par le profil de données indiquent plusieurs aspects à considérer :\n",
    "\n",
    "    Déséquilibre des variables catégorielles : Plusieurs variables présentent un déséquilibre important dans leurs modalités, ce qui peut biaiser les résultats des analyses et des modèles construits. Elles seront supprimées. \n",
    "\n",
    "    Données manquantes : Certaines variables contiennent un pourcentage non négligeable de valeurs manquantes. \n",
    "\n",
    "    Zéros dans les variables numériques : Plusieurs variables numériques présentent un pourcentage de zéros non négligeable. notemment les variables liées aux différents département de production. Certaines ont été supprimées. Par contre d'autre ont été maintenue du fait de la valeur ajoutée quelle apporte au film. C'est le cas par exemple de la variable 'production_crew_department_Visual Effects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ayedesso/9CEA8269EA823F8E/Travail_ubuntu/Autres_travaux/ML_dodo/venvir/lib/python3.10/site-packages/ydata_profiling/utils/dataframe.py:137: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={\"index\": \"df_index\"}, inplace=True)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43e85bf8501f482a85d178a33b56ff26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarize dataset:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee54a2f69eb448e8972d6675f4504422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generate report structure:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a53cb91948d4b40b94d1d2095e936c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render widgets:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f81a0db558b54743878b198aa42f3f27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Tab(children=(Tab(children=(GridBox(children=(VBox(children=(GridspecLayout(children=(HTML(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "357912bcb16248c4ae2e378e8aeeae34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Render HTML:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c60b20f41c421389d0bdf2eabd5d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Export report to file:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#dataset.describe()\n",
    "profile = ProfileReport(merged_dataset)\n",
    "profile.to_widgets()\n",
    "profile.to_file(\"rapport2.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse du deuxième rapport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après modification apportée à la base, cette étape consistera à analyser les corrélation entre la variables. Pour éviter la colinéarité, les variables indépendantes corrélées entre elles ont été analysées de près. Sur la base de la revu de litérrature, certaines ont été supprimées. Aussi, celle qui sont correlées avec la variables revenue sont supprimées. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41854/774090869.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_dataset.drop(columns=variables_a_supprimer3, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Liste des variables à supprimer\n",
    "variables_a_supprimer3 = ['Nb_modaliteproduction_crew_department', 'production_crew_department_Art' , 'production_crew_gender_0' ,\t'production_crew_gender_1'\t, 'production_crew_gender_2', 'vote_count' , 'popularity']\n",
    "\n",
    "# Supprimer les variables spécifiées\n",
    "merged_dataset.drop(columns=variables_a_supprimer3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41854/4212129339.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_dataset.drop(columns=variables_a_supprimer3, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Liste des variables à supprimer\n",
    "variables_a_supprimer3 = ['release' , 'countries_of_production' , 'production', 'title_y' , 'keywords']\n",
    "\n",
    "# Supprimer les variables spécifiées\n",
    "merged_dataset.drop(columns=variables_a_supprimer3, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes avant la suppression : 3395\n",
      "Nombre de lignes après la suppression : 3347\n",
      "Nombre de lignes supprimées : 48\n"
     ]
    }
   ],
   "source": [
    "# Nombre de lignes avant la suppression\n",
    "nb_lignes_avant = merged_dataset.shape[0]\n",
    "\n",
    "# Supprimer les lignes avec des valeurs manquantes\n",
    "merged_dataset_2 = merged_dataset.dropna()\n",
    "\n",
    "# Nombre de lignes après la suppression\n",
    "nb_lignes_apres = merged_dataset_2.shape[0]\n",
    "\n",
    "# Nombre de lignes supprimées\n",
    "nb_lignes_supprimees = nb_lignes_avant - nb_lignes_apres\n",
    "\n",
    "print(f'Nombre de lignes avant la suppression : {nb_lignes_avant}')\n",
    "print(f'Nombre de lignes après la suppression : {nb_lignes_apres}')\n",
    "print(f'Nombre de lignes supprimées : {nb_lignes_supprimees}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - 1 Scale numerical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB : RobustScaler a été préféré aux autres méthodes parce qu'elle est utile lorsque vos données contiennent des valeurs aberrantes ou des distributions non normale. Elle est moins sensible aux valeurs aberrantes que la standardisation et la mise à l'échelle min-max."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_41854/640773186.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  merged_dataset_2[caracteristiques_numeriques.columns] = scaler.fit_transform(caracteristiques_numeriques)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Créer une instance de RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Sélectionner les caractéristiques numériques à mettre à l'échelle (en excluant \"revenue\")\n",
    "caracteristiques_numeriques = merged_dataset_2.select_dtypes(include=['float64', 'int64']).drop(columns=['revenue'])\n",
    "\n",
    "# Appliquer RobustScaler aux caractéristiques sélectionnées\n",
    "merged_dataset_2[caracteristiques_numeriques.columns] = scaler.fit_transform(caracteristiques_numeriques)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2 Split the dataset into training, validation, and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_variables = merged_dataset_2.columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'ensemble d'entraînement : 1639\n",
      "Taille de l'ensemble de validation : 703\n",
      "Taille de l'ensemble de test : 1005\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparer les variables indépendantes (caractéristiques) de la variable dépendante (cible)\n",
    "X = merged_dataset_2.drop(columns=['revenue'])  # Caractéristiques\n",
    "y = merged_dataset_2['revenue']  # Variable cible\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement (70%) et de test (30%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Diviser l'ensemble d'entraînement en ensembles d'entraînement (70%) et de validation (30%)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)\n",
    "\n",
    "# Afficher les tailles des ensembles\n",
    "print(\"Taille de l'ensemble d'entraînement :\", X_train.shape[0])\n",
    "print(\"Taille de l'ensemble de validation :\", X_val.shape[0])\n",
    "print(\"Taille de l'ensemble de test :\", X_test.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Model Comparison and Hyperparameter selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ayedesso/9CEA8269EA823F8E/Travail_ubuntu/Autres_travaux/ML_dodo/venvir/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n",
      "/media/ayedesso/9CEA8269EA823F8E/Travail_ubuntu/Autres_travaux/ML_dodo/venvir/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression:\n",
      "Mean Absolute Error: 88134069.22\n",
      "Root Mean Squared Error: 144490860.75\n",
      "R-squared: 0.32\n",
      "-------------------------\n",
      "Decision Tree:\n",
      "Mean Absolute Error: 102209123.73\n",
      "Root Mean Squared Error: 169999396.01\n",
      "R-squared: 0.06\n",
      "-------------------------\n",
      "Random Forest:\n",
      "Mean Absolute Error: 84878019.62\n",
      "Root Mean Squared Error: 134830608.53\n",
      "R-squared: 0.41\n",
      "-------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/ayedesso/9CEA8269EA823F8E/Travail_ubuntu/Autres_travaux/ML_dodo/venvir/lib/python3.10/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Instancier les modèles\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Decision Tree': DecisionTreeRegressor(),\n",
    "    'Random Forest': RandomForestRegressor()\n",
    "}\n",
    "\n",
    "# Entraîner et évaluer chaque modèle\n",
    "for name, model in models.items():\n",
    "    # Entraîner le modèle\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Prédire sur les ensembles de validation\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Calculer les métriques d'évaluation\n",
    "    mae = mean_absolute_error(y_val, y_pred)\n",
    "    rmse = mean_squared_error(y_val, y_pred, squared=False)\n",
    "    r2 = r2_score(y_val, y_pred)\n",
    "    \n",
    "    # Afficher les résultats\n",
    "    print(f'{name}:')\n",
    "    print(f'Mean Absolute Error: {mae:.2f}')\n",
    "    print(f'Root Mean Squared Error: {rmse:.2f}')\n",
    "    print(f'R-squared: {r2:.2f}')\n",
    "    print('-------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Linear Regression :\n",
    "        L'erreur absolue moyenne (MAE) est assez élevée, indiquant que les prédictions de revenu sont en moyenne éloignées de 88,134,069.22.\n",
    "        L'erreur quadratique moyenne (RMSE) est également élevée, ce qui signifie que les prédictions peuvent avoir une variance élevée par rapport aux valeurs réelles.\n",
    "        La valeur de R carré (R-squared) de 0.32 indique que le modèle linéaire explique environ 32% de la variance totale dans les données, ce qui n'est pas très élevé.\n",
    "\n",
    "    Decision Tree :\n",
    "        Le modèle d'arbre de décision semble avoir de moins bonnes performances que la régression linéaire en termes d'erreurs absolues et quadratiques moyennes.\n",
    "        Le R carré est également assez bas, ce qui suggère que le modèle d'arbre de décision n'explique pas bien la variance des données.\n",
    "\n",
    "    Random Forest :\n",
    "        Le modèle de forêt aléatoire semble être le meilleur parmi les trois modèles évalués, avec la plus faible MAE et RMSE.\n",
    "        Le R carré de 0.41 est plus élevé que celui des autres modèles, indiquant une meilleure capacité à expliquer la variance des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6- Model Evaluation and Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Evaluation:\n",
      "Mean Absolute Error: 86498061.23263682\n",
      "Root Mean Squared Error: 159719033.11502746\n",
      "R-squared: 0.42169894371812866\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle sur l'ensemble de test\n",
    "final_model = RandomForestRegressor()  # Remplacer RandomForestRegressor() par votre modèle final\n",
    "final_model.fit(X_train, y_train)\n",
    "predictions = final_model.predict(X_test)\n",
    "\n",
    "# Calcul des métriques d'évaluation\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, predictions))\n",
    "r_squared = r2_score(y_test, predictions)\n",
    "\n",
    "print(\"Final Model Evaluation:\")\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(\"Root Mean Squared Error:\", rmse)\n",
    "print(\"R-squared:\", r_squared)\n",
    "print(\"-------------------------\")\n",
    "\n",
    "# Interprétation des prédictions du modèle\n",
    "# Vous pouvez utiliser des techniques d'analyse de SHAP, LIME, ou simplement examiner les coefficients (dans le cas de la régression linéaire) pour comprendre les facteurs qui influent sur les prédictions du modèle.\n",
    "\n",
    "# Discussion sur les limitations et biais potentiels du modèle\n",
    "# Il est important de discuter des limitations du modèle, telles que les biais de sélection des données, les variables omises, les hypothèses du modèle, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le R² de 0.42 est une indication modérée que le modèle explique une partie de la variance des données. Cependant, les valeurs absolues des erreurs (MAE et RMSE) indiquent que le modèle pourrait encore être amélioré pour fournir des prédictions plus précises."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvir",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
